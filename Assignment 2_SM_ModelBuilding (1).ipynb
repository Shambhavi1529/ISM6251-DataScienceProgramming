{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6509a759",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a7eb69",
   "metadata": {},
   "source": [
    "##### Predicting wethere the water quality is safe for drinking or not by building ML models such as Logistic regression, Support vector Machine(SVM) and Decision tree along with hyperparameter tuning to predict the chance of diabetes. Using Recall as a performance metric to judge our models.\n",
    "\n",
    "##### Choosing Recall as a performance metric helps to prioritise FALSE NEGATIVES where the model predicts the water is safe to drink but in reality it isn't, thus, creating a higher chance of risking lives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e407ee8a",
   "metadata": {},
   "source": [
    "### Lodaing the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7287bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(1)\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00446d60",
   "metadata": {},
   "source": [
    "### Loading the processed training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f54d490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('/Users/shambhavimishra/Downloads/X_train1.csv') \n",
    "y_train = pd.read_csv('/Users/shambhavimishra/Downloads/y_train1.csv') \n",
    "X_test = pd.read_csv('/Users/shambhavimishra/Downloads/X_test1.csv') \n",
    "y_test = pd.read_csv('/Users/shambhavimishra/Downloads/y_test1.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a1b70e0-5b93-46ae-a5c9-1f6afdf9febb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(898, 19)\n",
      "(898, 1)\n",
      "(300, 19)\n",
      "(300, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543eceea",
   "metadata": {},
   "source": [
    "### Building a dataframe to store our models performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "264e3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ea1ebc",
   "metadata": {},
   "source": [
    "### Implementing Logistic Regression model with hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb5de7d",
   "metadata": {},
   "source": [
    "##### Using Randomized search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab531c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found through Randomized Search CV: {'solver': 'saga', 'penalty': 'l1', 'max_iter': 1122, 'l1_ratio': 0.5, 'C': 1}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'penalty': ['l1', 'l2'], \n",
    "              'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'solver': ['liblinear', 'saga'],\n",
    "              'l1_ratio': [0.25, 0.5, 0.75],\n",
    "             'max_iter': np.arange(800, 1200)\n",
    "             }\n",
    "\n",
    "# Perform Randomized Search CV to find the best hyperparameters\n",
    "best_log_reg = RandomizedSearchCV(estimator=LogisticRegression(random_state=0, solver='saga'),\n",
    "                                      scoring='recall', \n",
    "                                      param_distributions=param_grid, \n",
    "                                      cv=5, \n",
    "                                      verbose=0, \n",
    "                                      return_train_score=True, \n",
    "                                      n_iter=30, \n",
    "                                      n_jobs=-1)\n",
    "best_log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found through Randomized Search CV\n",
    "print(f\"Best parameters found through Randomized Search CV: {best_log_reg.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771ba78",
   "metadata": {},
   "source": [
    "##### Performing GridSearch over a close range of parameters that we got from Randomized search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "831cea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found through Grid Search CV: {'C': 1, 'max_iter': 750, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for Grid Search CV\n",
    "param_grid = { \n",
    "    'solver': ['saga'],\n",
    "    'penalty': ['l2'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'max_iter': np.arange(750,950)\n",
    "}\n",
    "\n",
    "# Perform Grid Search CV with the best parameters from Randomized Search CV\n",
    "grid_log_reg = GridSearchCV(estimator=LogisticRegression(random_state=0, solver=best_log_reg.best_params_['solver']),\n",
    "                                param_grid=param_grid,\n",
    "                                scoring='recall',\n",
    "                                cv=5,\n",
    "                                n_jobs=-1)\n",
    "grid_log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found through Grid Search CV\n",
    "print(f\"Best parameters found through Grid Search CV: {grid_log_reg.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b841641",
   "metadata": {},
   "source": [
    "##### Storing the performance metrics in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "719b45df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found through Grid Search CV: {'C': 0.1, 'max_iter': 750, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for Grid Search CV\n",
    "param_grid = { \n",
    "    'solver': [best_log_reg.best_params_['solver']],\n",
    "    'penalty': [best_log_reg.best_params_['penalty']],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'max_iter': np.arange(750,950)\n",
    "}\n",
    "\n",
    "# Perform Grid Search CV with the best parameters from Randomized Search CV\n",
    "grid_lregression = GridSearchCV(estimator=LogisticRegression(random_state=0, solver=best_log_reg.best_params_['solver']),\n",
    "                                param_grid=param_grid,\n",
    "                                scoring='recall',\n",
    "                                cv=10,\n",
    "                                n_jobs=-1)\n",
    "grid_lregression.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found through Grid Search CV\n",
    "print(f\"Best parameters found through Grid Search CV: {grid_lregression.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c6ee8e7-d51f-4fe8-b1ee-b600c4f7b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the best parameters found through Grid Search CV \n",
    "c_matrix = confusion_matrix(y_test, grid_lregression.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model': \"LR\", \n",
    "                                                     'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                     'Precision': [TP/(TP+FP)], \n",
    "                                                     'Recall': [TP/(TP+FN)], \n",
    "                                                     'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                    }, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cc80e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.956284</td>\n",
       "      <td>0.866337</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  Accuracy  Precision    Recall        F1\n",
       "0    LR  0.883333   0.956284  0.866337  0.909091"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59e4e93",
   "metadata": {},
   "source": [
    "### Implementing SVM model with hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2238831d",
   "metadata": {},
   "source": [
    "##### Using Randomized search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fadadf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 140 candidates, totalling 700 fits\n",
      "The best recall score is 0.8530836454431959\n",
      "... with parameters: {'kernel': 'poly', 'gamma': 'auto', 'C': 2}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.arange(1,25),   \n",
    "    'gamma': ['scale','auto'],\n",
    "    'kernel':['linear','rbf','poly']\n",
    "}\n",
    "\n",
    "svm = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = svm, param_distributions=param_grid, cv=kfolds, n_iter=140,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba7e36",
   "metadata": {},
   "source": [
    "##### Performing GridSearch over a close range of parameters that we got from Randomized search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dc23035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "The best recall score is 0.8530836454431959\n",
      "... with parameters: {'C': 2, 'gamma': 'auto', 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "C = rand_search.best_params_['C']\n",
    "gamma = rand_search.best_params_['gamma']\n",
    "kernel = rand_search.best_params_['kernel']\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.arange(C-2,C+2),  \n",
    "    'gamma': [gamma],\n",
    "    'kernel': [kernel]\n",
    "    \n",
    "}\n",
    "\n",
    "svm1 = SVC()\n",
    "grid_search = GridSearchCV(estimator = svm1, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestprecision_SVM = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b7b2c8",
   "metadata": {},
   "source": [
    "##### Storing the performance metrics in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad2e0a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.956284</td>\n",
       "      <td>0.866337</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.811881</td>\n",
       "      <td>0.841026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  Accuracy  Precision    Recall        F1\n",
       "0    LR  0.883333   0.956284  0.866337  0.909091\n",
       "0   SVM  0.793333   0.872340  0.811881  0.841026"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"SVM\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd2981f",
   "metadata": {},
   "source": [
    "### Implementing Decision Tree model with hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d173302a",
   "metadata": {},
   "source": [
    "##### Using Randomized search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fc198fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best recall score is 0.8485892634207242\n",
      "... with parameters: {'min_samples_split': 36, 'min_samples_leaf': 17, 'min_impurity_decrease': 0.0091, 'max_leaf_nodes': 31, 'max_depth': 14, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(2,50),  \n",
    "    'min_samples_leaf': np.arange(1,50),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 50), \n",
    "    'max_depth': np.arange(1,20), \n",
    "    'criterion': ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator=dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                                 scoring=score_measure, verbose=1, n_jobs=-1, # n_jobs=-1 will utilize all available CPUs \n",
    "                                 return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestPrecTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817e7b40",
   "metadata": {},
   "source": [
    "##### Performing GridSearch over a close range of parameters that we got from Randomized search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ecf1377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 320 candidates, totalling 1600 fits\n",
      "The best recall score is 0.8397003745318352\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 15, 'max_leaf_nodes': 30, 'min_impurity_decrease': 0.0005, 'min_samples_leaf': 13, 'min_samples_split': 33}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(26,36),  \n",
    "    'min_samples_leaf': np.arange(8,16),\n",
    "    'min_impurity_decrease': np.arange( 0.0005, 0.0010, 0.0020),\n",
    "    'max_leaf_nodes': [10,30], \n",
    "    'max_depth': [5,15], \n",
    "    'criterion': ['entropy']\n",
    "}\n",
    "\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66773553",
   "metadata": {},
   "source": [
    "##### Storing the performance metrics in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7658ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.956284</td>\n",
       "      <td>0.866337</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.811881</td>\n",
       "      <td>0.841026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.816832</td>\n",
       "      <td>0.850515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  Accuracy  Precision    Recall        F1\n",
       "0             LR  0.883333   0.956284  0.866337  0.909091\n",
       "0            SVM  0.793333   0.872340  0.811881  0.841026\n",
       "0  Decision Tree  0.806667   0.887097  0.816832  0.850515"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision Tree\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6236dc3c-4a81-41f4-af8b-193c7879e980",
   "metadata": {},
   "source": [
    "### Implementing Neural Network model with hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00a1cd6e-3f35-42f0-98b7-b690522eed25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.34 s\n",
      "Wall time: 2.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40), solver='adam', max_iter=200) #max_iter - how often we are changing the w's(weight)\n",
    "_ = ann.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90019c87-61e5-4b68-a2c1-1a1b5cc3a869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3dedef4-ec9a-4161-8eca-619bdc308c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73        98\n",
      "           1       0.87      0.87      0.87       202\n",
      "\n",
      "    accuracy                           0.83       300\n",
      "   macro avg       0.80      0.80      0.80       300\n",
      "weighted avg       0.83      0.83      0.83       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a53a63b-dd9d-4724-8f17-c251ccc1b49d",
   "metadata": {},
   "source": [
    "##### NN model with RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b748e1ed-93f1-4a92-a069-2479971a1408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'solver': 'adam', 'max_iter': 5000, 'learning_rate_init': 0.01, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (70,), 'alpha': 0.2, 'activation': 'tanh'}\n",
      "CPU times: total: 3.61 s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20), (70,50,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],     #regulization term\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d06ec379-b4ce-4bcd-9ead-808aaf784cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77        98\n",
      "           1       0.90      0.87      0.88       202\n",
      "\n",
      "    accuracy                           0.85       300\n",
      "   macro avg       0.82      0.83      0.83       300\n",
      "weighted avg       0.85      0.85      0.85       300\n",
      "\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 16.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c88eb4b-6cce-4f06-8c98-023308418978",
   "metadata": {},
   "source": [
    "##### NN model with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16e1ae37-3255-40bc-b7c0-9806e6b45401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "{'activation': 'tanh', 'alpha': 0.5, 'hidden_layer_sizes': (90,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'max_iter': 5000, 'solver': 'adam'}\n",
      "CPU times: total: 4.44 s\n",
      "Wall time: 55.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (30,), (50,), (70,), (90,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3b0135d-b8a1-42fb-b2d2-a0dd94c8116c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79        98\n",
      "           1       0.91      0.88      0.89       202\n",
      "\n",
      "    accuracy                           0.86       300\n",
      "   macro avg       0.84      0.85      0.84       300\n",
      "weighted avg       0.86      0.86      0.86       300\n",
      "\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 15.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14bdbb6c-9d07-442b-9759-431e9d3586e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.956284</td>\n",
       "      <td>0.866337</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.811881</td>\n",
       "      <td>0.841026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.816832</td>\n",
       "      <td>0.850515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.908163</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.894472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  Accuracy  Precision    Recall        F1\n",
       "0              LR  0.883333   0.956284  0.866337  0.909091\n",
       "0             SVM  0.793333   0.872340  0.811881  0.841026\n",
       "0   Decision Tree  0.806667   0.887097  0.816832  0.850515\n",
       "0  Neural Network  0.860000   0.908163  0.881188  0.894472"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Neural Network\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f27635",
   "metadata": {},
   "source": [
    "# Using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b98dbb5",
   "metadata": {},
   "source": [
    "### Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1e11606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - 1s 26ms/step - loss: 2.2005 - accuracy: 0.3519 - val_loss: 1.9018 - val_accuracy: 0.6600\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.8344 - accuracy: 0.5067 - val_loss: 1.5163 - val_accuracy: 0.6800\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.4253 - accuracy: 0.5356 - val_loss: 1.0730 - val_accuracy: 0.6867\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.9837 - accuracy: 0.6459 - val_loss: 0.7338 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.7294 - val_loss: 0.5920 - val_accuracy: 0.7200\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7673 - val_loss: 0.4799 - val_accuracy: 0.7733\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7951 - val_loss: 0.4336 - val_accuracy: 0.8033\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.8263 - val_loss: 0.3951 - val_accuracy: 0.8267\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3675 - accuracy: 0.8385 - val_loss: 0.3773 - val_accuracy: 0.8333\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3419 - accuracy: 0.8519 - val_loss: 0.3351 - val_accuracy: 0.8467\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.8552 - val_loss: 0.3383 - val_accuracy: 0.8467\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2946 - accuracy: 0.8775 - val_loss: 0.3271 - val_accuracy: 0.8467\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2773 - accuracy: 0.8853 - val_loss: 0.3279 - val_accuracy: 0.8633\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2647 - accuracy: 0.8764 - val_loss: 0.3266 - val_accuracy: 0.8533\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2515 - accuracy: 0.9009 - val_loss: 0.3298 - val_accuracy: 0.8567\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2361 - accuracy: 0.9109 - val_loss: 0.3224 - val_accuracy: 0.8733\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2272 - accuracy: 0.9220 - val_loss: 0.3311 - val_accuracy: 0.8700\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2167 - accuracy: 0.9232 - val_loss: 0.3260 - val_accuracy: 0.8667\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.2055 - accuracy: 0.9310 - val_loss: 0.3422 - val_accuracy: 0.8667\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1965 - accuracy: 0.9343 - val_loss: 0.3417 - val_accuracy: 0.8667\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# create model stucture\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(shape=(19,))) # update input shape\n",
    "model.add(keras.layers.Dense(50, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal()))\n",
    "model.add(keras.layers.Dense(50, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal()))\n",
    "model.add(keras.layers.Dense(50, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal()))\n",
    "model.add(keras.layers.Dense(10, activation='softmax', kernel_initializer=tf.keras.initializers.GlorotNormal())) # final layer, 10 categories\n",
    "\n",
    "# compile\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# if you want to overide the defaults for the optimizer....\n",
    "#adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "# fit the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=20, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b7260f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.34170570969581604, 0.8666666746139526]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "scores\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97464a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.34\n",
      "accuracy: 86.67%\n"
     ]
    }
   ],
   "source": [
    "# let's format this into a better output...\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144f750d",
   "metadata": {},
   "source": [
    "### Wide and Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "209439fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define the model: for multi-class\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(shape=(19,))) # update input shape\n",
    "model.add(keras.layers.Dense(100, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model.add(keras.layers.Dense(100, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model.add(keras.layers.Dense(100, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax', kernel_initializer='glorot_normal'))\n",
    "\n",
    "# Compile model\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "312c35e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - 1s 23ms/step - loss: 0.8678 - accuracy: 0.6481 - val_loss: 0.3443 - val_accuracy: 0.8367\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3385 - accuracy: 0.8597 - val_loss: 0.3134 - val_accuracy: 0.8633\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2860 - accuracy: 0.8675 - val_loss: 0.4026 - val_accuracy: 0.8500\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.2286 - accuracy: 0.9076 - val_loss: 0.4021 - val_accuracy: 0.8433\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1867 - accuracy: 0.9187 - val_loss: 0.3605 - val_accuracy: 0.8533\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1456 - accuracy: 0.9443 - val_loss: 0.4743 - val_accuracy: 0.8267\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.1143 - accuracy: 0.9633 - val_loss: 0.5296 - val_accuracy: 0.8267\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.9633 - val_loss: 0.5949 - val_accuracy: 0.8267\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9777 - val_loss: 0.6147 - val_accuracy: 0.8200\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0463 - accuracy: 0.9866 - val_loss: 0.7344 - val_accuracy: 0.8167\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 0.9933 - val_loss: 0.9086 - val_accuracy: 0.8067\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 0.9860 - val_accuracy: 0.8133\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0102 - accuracy: 0.9978 - val_loss: 0.9972 - val_accuracy: 0.7933\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.1893 - val_accuracy: 0.8233\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.2053 - val_accuracy: 0.8033\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 1.2263 - val_accuracy: 0.8100\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9955 - val_loss: 1.3083 - val_accuracy: 0.8200\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0441 - accuracy: 0.9844 - val_loss: 1.3301 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1306 - accuracy: 0.9644 - val_loss: 1.1933 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.1636 - accuracy: 0.9555 - val_loss: 0.6881 - val_accuracy: 0.8100\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "941c1f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.69\n",
      "Accuracy: 81.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Loss: %.2f\" % scores[0])\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0498c567",
   "metadata": {},
   "source": [
    "## RandomGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0de3a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# If you don't have the following installed, from command line '!pip install scikeras'\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.initializers import GlorotNormal\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "def build_clf(hidden_layer_sizes, dropout):\n",
    "    ann = tf.keras.models.Sequential()\n",
    "    ann.add(keras.layers.Input(shape=19)),\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, kernel_initializer= tf.keras.initializers.GlorotUniform(), \n",
    "                                     bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    ann.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    ann.compile(loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return ann\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23a3499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=19,\n",
    "    dropout = 0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9ef18ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'hidden_layer_sizes', 'dropout', 'class_weight'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    'optimizer__learning_rate': [0.0005, 0.001, 0.005],\n",
    "    'model__hidden_layer_sizes': [(70,),(90, ), (100,), (100, 90)],\n",
    "    'model__dropout': [0, 0.1],\n",
    "    'batch_size':[20, 60, 100],\n",
    "    'epochs':[10, 50, 100],\n",
    "    'optimizer':[\"adam\",'sgd']\n",
    "}\n",
    "keras_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6fb9bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 992us/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 979us/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B850B57760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B850CE2830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 906us/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 873us/step\n",
      "9/9 [==============================] - 0s 875us/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 999us/step\n",
      "9/9 [==============================] - 0s 929us/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1000us/step\n",
      "9/9 [==============================] - 0s 919us/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 702us/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 824us/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 0s/step\n",
      "9/9 [==============================] - 0s 923us/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 959us/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 902us/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 874us/step\n",
      "9/9 [==============================] - 0s 956us/step\n",
      "9/9 [==============================] - 0s 963us/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 9ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 985us/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 0s/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 875us/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "9/9 [==============================] - 0s 0s/step\n",
      "9/9 [==============================] - 0s 875us/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 874us/step\n",
      "9/9 [==============================] - 0s 999us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 0s/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 406us/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 732us/step\n",
      "9/9 [==============================] - 0s 3ms/step\n",
      "9/9 [==============================] - 0s 1ms/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 875us/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "9/9 [==============================] - 0s 0s/step\n",
      "9/9 [==============================] - 0s 775us/step\n",
      "9/9 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(estimator=keras_clf, param_distributions=params, scoring='accuracy', n_iter=50, cv=5)\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(10000) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "callback = [earlystop]\n",
    "\n",
    "_ = rnd_search_cv.fit(X_train, y_train, callbacks=callback, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c9c4c1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer__learning_rate': 0.0005,\n",
       " 'optimizer': 'sgd',\n",
       " 'model__hidden_layer_sizes': (100,),\n",
       " 'model__dropout': 0.1,\n",
       " 'epochs': 100,\n",
       " 'batch_size': 60}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8cae50e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer__learning_rate': 0.0005, 'optimizer': 'sgd', 'model__hidden_layer_sizes': (100,), 'model__dropout': 0.1, 'epochs': 100, 'batch_size': 60}\n"
     ]
    }
   ],
   "source": [
    "best_net = rnd_search_cv.best_estimator_\n",
    "print(rnd_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1755f739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.94      0.81        98\n",
      "           1       0.96      0.82      0.88       202\n",
      "\n",
      "    accuracy                           0.86       300\n",
      "   macro avg       0.84      0.88      0.85       300\n",
      "weighted avg       0.88      0.86      0.86       300\n",
      "\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 87.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = best_net.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d61e8b-8117-4c8e-bbdc-50936388a239",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "#### The models used: Logistic regression with hyperparameter tuning, SVM model with hyperparameter tuning, Decision Tree with hyperparameter tuning, Neural Network with randomsearchcv and gridsearchcv, Deep Network, Wide and Deep Neural Network with randomsearchcv.\n",
    "\n",
    "Looking at the performance metric, the hightest Accuracy is of the Linear Regression Model(88.3%), then Wide & Deep Neural Network (86.67%), Neural Network (84.3%), followed by Decision Tree(80.6%) and SVM(84.3%).\n",
    "\n",
    "Looking at the performance metric, the hightest Precision is of the Wide & Deep Neural Network (96%), then Linear Regression Model(95.6%), then Neural Network(90.1%), followed by Decision Tree(88.7%) and SVM(87.2%).\n",
    "\n",
    "Looking at the performance metric, the hightest Recall is of the Linear Regression Model(86.6%), then Neural Network(86.1%), followed by Decision Tree(81.6%), SVM(81.1%) and Wide & Deep Neural Network(81%).\n",
    "\n",
    "Looking at the performance metric, the hightest F1 is of the Linear Regression Model(90.9%), then Neural Network(88.1%), Wide & Deep Neural Network(88%), followed by Decision Tree(85.1%) and SVM(84.1%).\n",
    "\n",
    "##### Thus, it is evident that Linear Regression Model is the best model for predicting whether the water is safe or not as it has an the best performance matric scores(Accuracy, Precision, Recall, F1) compared to the SVM, Decision Tree and Neural Network Model, Deep Neural Network and Wide & Deep Neural Network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1911e4-9800-4591-9f4d-b480aa2e15d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
